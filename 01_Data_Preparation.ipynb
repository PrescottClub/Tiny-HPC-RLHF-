{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 1. Data Preparation for RLHF\n",
        "\n",
        "This notebook handles the download, processing, and preparation of our dataset for RLHF training. We'll be working with the Anthropic/hh-rlhf dataset to create properly formatted preference pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import random\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration variables - easy to adjust for experiments\n",
        "DATASET_NAME = 'Anthropic/hh-rlhf'\n",
        "NUM_SAMPLES_TRAIN = 5000\n",
        "NUM_SAMPLES_TEST = 1000\n",
        "OUTPUT_DIR = 'data'\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Training samples: {NUM_SAMPLES_TRAIN}\")\n",
        "print(f\"Test samples: {NUM_SAMPLES_TEST}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the raw dataset from Hugging Face Hub\n",
        "print(\"Loading dataset from Hugging Face Hub...\")\n",
        "raw_dataset = load_dataset(DATASET_NAME)\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(raw_dataset)\n",
        "\n",
        "print(\"\\nDataset info:\")\n",
        "for split in raw_dataset.keys():\n",
        "    print(f\"{split}: {len(raw_dataset[split])} examples\")\n",
        "    \n",
        "# Show an example to understand the data format\n",
        "print(\"\\nExample from training set:\")\n",
        "example = raw_dataset['train'][0]\n",
        "print(f\"Keys: {list(example.keys())}\")\n",
        "print(f\"\\nChosen text (first 200 chars): {example['chosen'][:200]}...\")\n",
        "print(f\"\\nRejected text (first 200 chars): {example['rejected'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create smaller, manageable subsets for experiments\n",
        "print(\"Creating sampled datasets...\")\n",
        "\n",
        "# Shuffle for reproducibility and sample\n",
        "train_sampled = raw_dataset['train'].shuffle(seed=42).select(range(NUM_SAMPLES_TRAIN))\n",
        "test_sampled = raw_dataset['test'].shuffle(seed=42).select(range(NUM_SAMPLES_TEST))\n",
        "\n",
        "print(f\"\\nSampled dataset sizes:\")\n",
        "print(f\"Training set: {len(train_sampled)} examples\")\n",
        "print(f\"Test set: {len(test_sampled)} examples\")\n",
        "\n",
        "print(\"\\nSampling complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define preprocessing logic\n",
        "def preprocess_example(example):\n",
        "    \"\"\"\n",
        "    Preprocess a single example from the hh-rlhf dataset.\n",
        "    \n",
        "    Args:\n",
        "        example: Dict with 'chosen' and 'rejected' fields\n",
        "        \n",
        "    Returns:\n",
        "        Dict with 'prompt', 'chosen', and 'rejected' fields\n",
        "    \"\"\"\n",
        "    \n",
        "    def extract_prompt_and_response(text):\n",
        "        \"\"\"Extract prompt and response from conversation text\"\"\"\n",
        "        try:\n",
        "            # Find the last occurrence of \"\\n\\nAssistant:\"\n",
        "            assistant_marker = \"\\n\\nAssistant:\"\n",
        "            last_assistant_idx = text.rfind(assistant_marker)\n",
        "            \n",
        "            if last_assistant_idx == -1:\n",
        "                # Fallback: try \"Assistant:\" without double newlines\n",
        "                assistant_marker = \"Assistant:\"\n",
        "                last_assistant_idx = text.rfind(assistant_marker)\n",
        "                \n",
        "            if last_assistant_idx == -1:\n",
        "                # If no Assistant marker found, treat whole text as response\n",
        "                return \"\", text.strip()\n",
        "            \n",
        "            # Split into prompt and response\n",
        "            prompt = text[:last_assistant_idx].strip()\n",
        "            response = text[last_assistant_idx + len(assistant_marker):].strip()\n",
        "            \n",
        "            return prompt, response\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing text: {e}\")\n",
        "            return \"\", text.strip()\n",
        "    \n",
        "    # Process chosen and rejected responses\n",
        "    chosen_text = example['chosen']\n",
        "    rejected_text = example['rejected']\n",
        "    \n",
        "    # Extract prompt and responses\n",
        "    prompt_chosen, chosen_response = extract_prompt_and_response(chosen_text)\n",
        "    prompt_rejected, rejected_response = extract_prompt_and_response(rejected_text)\n",
        "    \n",
        "    # Use the chosen prompt (they should be the same)\n",
        "    prompt = prompt_chosen if prompt_chosen else prompt_rejected\n",
        "    \n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'chosen': chosen_response,\n",
        "        'rejected': rejected_response\n",
        "    }\n",
        "\n",
        "# Test the function with an example\n",
        "print(\"Testing preprocessing function...\")\n",
        "test_example = train_sampled[0]\n",
        "processed = preprocess_example(test_example)\n",
        "\n",
        "print(f\"\\nOriginal chosen text (first 150 chars): {test_example['chosen'][:150]}...\")\n",
        "print(f\"\\nProcessed:\")\n",
        "print(f\"Prompt (first 100 chars): {processed['prompt'][:100]}...\")\n",
        "print(f\"Chosen (first 100 chars): {processed['chosen'][:100]}...\")\n",
        "print(f\"Rejected (first 100 chars): {processed['rejected'][:100]}...\")\n",
        "\n",
        "print(\"\\nPreprocessing function ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing and save data\n",
        "print(\"Applying preprocessing to datasets...\")\n",
        "\n",
        "# Apply preprocessing function to both datasets\n",
        "train_processed = train_sampled.map(preprocess_example)\n",
        "test_processed = test_sampled.map(preprocess_example)\n",
        "\n",
        "print(\"Preprocessing complete!\")\n",
        "\n",
        "# Define output file paths\n",
        "train_output_path = os.path.join(OUTPUT_DIR, 'train_prefs.jsonl')\n",
        "test_output_path = os.path.join(OUTPUT_DIR, 'test_prefs.jsonl')\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Save processed datasets to disk\n",
        "print(f\"\\nSaving datasets...\")\n",
        "train_processed.to_json(train_output_path)\n",
        "test_processed.to_json(test_output_path)\n",
        "\n",
        "print(f\"\\n‚úÖ Data preparation complete!\")\n",
        "print(f\"Training data saved to: {train_output_path}\")\n",
        "print(f\"Test data saved to: {test_output_path}\")\n",
        "print(f\"\\nDataset sizes:\")\n",
        "print(f\"Training: {len(train_processed)} examples\")\n",
        "print(f\"Test: {len(test_processed)} examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify saved data\n",
        "print(\"Verifying saved data...\")\n",
        "\n",
        "# Load the saved training data back\n",
        "train_output_path = os.path.join(OUTPUT_DIR, 'train_prefs.jsonl')\n",
        "loaded_dataset = load_dataset('json', data_files=train_output_path)['train']\n",
        "\n",
        "print(f\"\\nLoaded dataset size: {len(loaded_dataset)}\")\n",
        "print(f\"\\nFirst example from loaded dataset:\")\n",
        "first_example = loaded_dataset[0]\n",
        "\n",
        "print(f\"\\nKeys: {list(first_example.keys())}\")\n",
        "print(f\"\\nPrompt: {first_example['prompt'][:200]}...\")\n",
        "print(f\"\\nChosen response: {first_example['chosen'][:200]}...\")\n",
        "print(f\"\\nRejected response: {first_example['rejected'][:200]}...\")\n",
        "\n",
        "# Verify the format is correct\n",
        "required_keys = {'prompt', 'chosen', 'rejected'}\n",
        "actual_keys = set(first_example.keys())\n",
        "\n",
        "if required_keys.issubset(actual_keys):\n",
        "    print(\"\\n‚úÖ Data format verification passed!\")\n",
        "    print(\"‚úÖ Your dataset is ready for RLHF training!\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Missing keys: {required_keys - actual_keys}\")\n",
        "    \n",
        "print(f\"\\nüéâ Data preparation and verification complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
