# EdgeRLHF Project Configuration
# ===================================

[project]
name = "EdgeRLHF"
version = "1.0.0"
description = "RLHF Pipeline for Consumer GPUs"
author = "EdgeRLHF Research Team"

[hardware]
target_gpu = "RTX 4060"
vram_limit = "8GB"
system_ram = "16GB+"

[training]
# Memory optimization settings
batch_size = 32
mini_batch_size = 2
gradient_accumulation_steps = 4
max_response_length = 64
forward_batch_size = 8

# Quantization options
precision_levels = ["bf16", "int8", "int4"]
default_precision = "bf16"

[models]
base_model = "distilgpt2"
sft_rank = 16
rm_quantization = ["bf16", "int8", "int4"]

[data]
max_train_samples = 1000
max_test_samples = 1000
dataset_source = "anthropic/hh-rlhf"

[paths]
models_dir = "./models/"
data_dir = "./data/"
results_dir = "./results/"
logs_dir = "./logs/"

[safety]
# RLHF safety parameters
kl_penalty = 0.2
max_kl_divergence = 0.5
reward_clip = 5.0
value_clip = 0.2

[optimization]
# For RTX 4060 8GB VRAM
enable_gradient_checkpointing = true
use_lora = true
enable_quantization = true
cpu_offload = false 