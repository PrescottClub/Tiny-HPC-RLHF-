"""
EdgeRLHFé¡¹ç›®é…ç½®ä¸­å¿ƒ
ç»Ÿä¸€ç®¡ç†æ‰€æœ‰è¶…å‚æ•°ã€è·¯å¾„å’Œå®éªŒé…ç½®
"""

import os
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional

# ============================================================================
# é¡¹ç›®è·¯å¾„é…ç½®
# ============================================================================

PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "data"
MODELS_DIR = PROJECT_ROOT / "models"
RESULTS_DIR = PROJECT_ROOT / "results"
LOGS_DIR = PROJECT_ROOT / "logs"

# ç¡®ä¿ç›®å½•å­˜åœ¨
for dir_path in [DATA_DIR, MODELS_DIR, RESULTS_DIR, LOGS_DIR]:
    dir_path.mkdir(exist_ok=True)

# ============================================================================
# æ¨¡å‹é…ç½®
# ============================================================================

@dataclass
class ModelConfig:
    """åŸºç¡€æ¨¡å‹é…ç½®"""
    base_model_name: str = "distilgpt2"
    model_max_length: int = 512
    pad_token: str = "<|endoftext|>"
    device_map: str = "auto"
    torch_dtype: str = "bfloat16"

@dataclass
class SFTConfig:
    """ç›‘ç£å¾®è°ƒé…ç½®"""
    # è®­ç»ƒå‚æ•°
    learning_rate: float = 2e-5
    batch_size: int = 4
    gradient_accumulation_steps: int = 4
    num_train_epochs: int = 3
    max_grad_norm: float = 1.0
    warmup_steps: int = 100
    logging_steps: int = 10
    save_steps: int = 500
    eval_steps: int = 500
    
    # LoRAé…ç½®
    lora_r: int = 16
    lora_alpha: int = 32
    lora_dropout: float = 0.1
    target_modules: List[str] = field(default_factory=lambda: ["c_attn", "c_proj"])
    
    # æ•°æ®é…ç½®
    max_length: int = 512
    train_on_inputs: bool = False

@dataclass
class RewardModelConfig:
    """å¥–åŠ±æ¨¡å‹é…ç½®"""
    # è®­ç»ƒå‚æ•°
    learning_rate: float = 1e-5
    batch_size: int = 8
    gradient_accumulation_steps: int = 2
    num_train_epochs: int = 2
    max_grad_norm: float = 1.0
    warmup_steps: int = 50
    logging_steps: int = 10
    save_steps: int = 200
    eval_steps: int = 200
    
    # é‡åŒ–é…ç½®
    quantization_precisions: List[str] = field(default_factory=lambda: ["bf16", "int8", "int4"])
    load_in_8bit: bool = False
    load_in_4bit: bool = False
    
    # æ•°æ®é…ç½®
    max_length: int = 512

@dataclass
class PPOConfig:
    """PPOå¯¹é½é…ç½®"""
    # åŸºç¡€PPOå‚æ•°
    learning_rate: float = 1.41e-5
    batch_size: int = 32
    mini_batch_size: int = 2
    gradient_accumulation_steps: int = 4
    max_grad_norm: float = 0.5
    
    # PPOç‰¹å®šå‚æ•°
    kl_penalty: str = "kl"
    adap_kl_ctrl: bool = True
    init_kl_coef: float = 0.1
    target_kl: float = 6.0
    gamma: float = 1.0
    lam: float = 0.95
    cliprange: float = 0.2
    cliprange_value: float = 0.2
    vf_coef: float = 0.1
    
    # ç”Ÿæˆå‚æ•°
    forward_batch_size: int = 8
    response_length: int = 64
    temperature: float = 1.0
    do_sample: bool = True
    top_k: int = 50
    top_p: float = 0.95

# ============================================================================
# å®éªŒé…ç½®
# ============================================================================

@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®"""
    # å®éªŒåŸºæœ¬ä¿¡æ¯
    experiment_name: str = "edgerlhf_experiment"
    seed: int = 42
    device: str = "cuda"
    
    # æ•°æ®é…ç½®
    dataset_name: str = "Anthropic/hh-rlhf"
    train_split: str = "train"
    test_split: str = "test"
    max_train_samples: Optional[int] = 10000
    max_eval_samples: Optional[int] = 1000
    
    # è¯„ä¼°é…ç½®
    eval_batch_size: int = 8
    eval_accumulation_steps: int = 1
    metric_for_best_model: str = "eval_loss"
    greater_is_better: bool = False
    
    # ä¿å­˜é…ç½®
    output_dir: str = str(MODELS_DIR)
    save_total_limit: int = 3
    load_best_model_at_end: bool = True
    save_strategy: str = "steps"
    evaluation_strategy: str = "steps"
    
    # æ—¥å¿—é…ç½®
    logging_dir: str = str(LOGS_DIR)
    report_to: List[str] = field(default_factory=list)  # ["wandb", "tensorboard"]
    logging_first_step: bool = True
    
    # å†…å­˜ä¼˜åŒ–
    dataloader_pin_memory: bool = True
    dataloader_num_workers: int = 0
    gradient_checkpointing: bool = True
    fp16: bool = False
    bf16: bool = True

# ============================================================================
# ç¡¬ä»¶é…ç½®
# ============================================================================

@dataclass
class HardwareConfig:
    """ç¡¬ä»¶é…ç½® - é’ˆå¯¹RTX 4060 8GBä¼˜åŒ–"""
    gpu_name: str = "RTX 4060"
    vram_gb: int = 8
    
    # å†…å­˜ä¼˜åŒ–è®¾ç½®
    max_memory_allocation: float = 0.85  # 85%çš„VRAM
    cpu_offload: bool = True
    pin_memory: bool = True
    
    # æ‰¹å¤„ç†å¤§å°å»ºè®®
    sft_recommended_batch_size: int = 4
    rm_recommended_batch_size: int = 8
    ppo_recommended_batch_size: int = 32
    
    # ç²¾åº¦å»ºè®®
    recommended_dtype: str = "bfloat16"
    use_gradient_checkpointing: bool = True

# ============================================================================
# å…¨å±€é…ç½®å®ä¾‹
# ============================================================================

# åˆ›å»ºé…ç½®å®ä¾‹
MODEL_CONFIG = ModelConfig()
SFT_CONFIG = SFTConfig()
REWARD_MODEL_CONFIG = RewardModelConfig()
PPO_CONFIG = PPOConfig()
EXPERIMENT_CONFIG = ExperimentConfig()
HARDWARE_CONFIG = HardwareConfig()

# ============================================================================
# é…ç½®éªŒè¯å’Œå®ç”¨å‡½æ•°
# ============================================================================

def get_model_path(model_type: str, precision: str = None) -> Path:
    """è·å–æ¨¡å‹ä¿å­˜è·¯å¾„"""
    if model_type == "sft":
        return MODELS_DIR / "sft"
    elif model_type == "rm":
        if precision:
            return MODELS_DIR / "rm" / precision
        return MODELS_DIR / "rm"
    elif model_type == "ppo":
        if precision:
            return MODELS_DIR / f"ppo_policy_{precision}"
        return MODELS_DIR / "ppo_policy"
    else:
        raise ValueError(f"Unknown model type: {model_type}")

def get_data_path(data_type: str) -> Path:
    """è·å–æ•°æ®æ–‡ä»¶è·¯å¾„"""
    if data_type == "train":
        return DATA_DIR / "train_prefs.jsonl"
    elif data_type == "test":
        return DATA_DIR / "test_prefs.jsonl"
    else:
        raise ValueError(f"Unknown data type: {data_type}")

def get_results_path(experiment_name: str) -> Path:
    """è·å–å®éªŒç»“æœè·¯å¾„"""
    return RESULTS_DIR / experiment_name

def validate_hardware_config():
    """éªŒè¯ç¡¬ä»¶é…ç½®æ˜¯å¦åˆç†"""
    import torch
    
    if torch.cuda.is_available():
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if total_memory < HARDWARE_CONFIG.vram_gb * 0.9:
            print(f"âš ï¸ Warning: Detected VRAM ({total_memory:.1f}GB) is less than configured ({HARDWARE_CONFIG.vram_gb}GB)")
    else:
        print("âš ï¸ Warning: CUDA not available")

def print_config_summary():
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("ğŸ”§ EdgeRLHF Configuration Summary")
    print("=" * 50)
    print(f"ğŸ“ Project Root: {PROJECT_ROOT}")
    print(f"ğŸ¤– Base Model: {MODEL_CONFIG.base_model_name}")
    print(f"ğŸ¯ Hardware Target: {HARDWARE_CONFIG.gpu_name} ({HARDWARE_CONFIG.vram_gb}GB)")
    print(f"ğŸ“Š Batch Sizes - SFT: {SFT_CONFIG.batch_size}, RM: {REWARD_MODEL_CONFIG.batch_size}, PPO: {PPO_CONFIG.batch_size}")
    print(f"âš¡ Precision: {MODEL_CONFIG.torch_dtype}")
    print("=" * 50)

if __name__ == "__main__":
    print_config_summary()
    validate_hardware_config() 