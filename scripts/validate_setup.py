#!/usr/bin/env python
"""
EdgeRLHFé¡¹ç›®éªŒè¯è„šæœ¬
éªŒè¯ç¯å¢ƒé…ç½®ã€æ•°æ®å®Œæ•´æ€§å’Œæ¨¡å‹å¯ç”¨æ€§
"""

import sys
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Any
import importlib

def check_environment() -> Dict[str, Any]:
    """æ£€æŸ¥åŸºç¡€ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥åŸºç¡€ç¯å¢ƒ...")
    
    results = {}
    
    # Pythonç‰ˆæœ¬
    version = sys.version_info
    results['python_version'] = f"{version.major}.{version.minor}.{version.micro}"
    python_ok = version.major == 3 and version.minor >= 9
    print(f"   Pythonç‰ˆæœ¬: {results['python_version']} {'âœ…' if python_ok else 'âŒ'}")
    results['python_ok'] = python_ok
    
    # CUDAæ£€æŸ¥
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            results['cuda_version'] = torch.version.cuda
            results['gpu_name'] = torch.cuda.get_device_name(0)
            results['gpu_memory'] = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   CUDAç‰ˆæœ¬: {results['cuda_version']} âœ…")
            print(f"   GPUè®¾å¤‡: {results['gpu_name']} âœ…")
            print(f"   GPUå†…å­˜: {results['gpu_memory']:.1f} GB âœ…")
        else:
            print("   CUDA: ä¸å¯ç”¨ âŒ")
        results['cuda_available'] = cuda_available
    except ImportError:
        print("   PyTorch: æœªå®‰è£… âŒ")
        results['cuda_available'] = False
    
    return results

def check_packages() -> Dict[str, bool]:
    """æ£€æŸ¥å¿…éœ€åŒ…"""
    print("\nğŸ“¦ æ£€æŸ¥å¿…éœ€åŒ…...")
    
    required_packages = {
        'torch': 'PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶',
        'transformers': 'HuggingFace Transformers',
        'datasets': 'HuggingFaceæ•°æ®é›†',
        'accelerate': 'åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿ',
        'peft': 'å‚æ•°é«˜æ•ˆå¾®è°ƒ',
        'trl': 'å¼ºåŒ–å­¦ä¹ è®­ç»ƒ',
        'bitsandbytes': 'é‡åŒ–åº“',
        'numpy': 'æ•°å€¼è®¡ç®—',
        'pandas': 'æ•°æ®å¤„ç†',
        'matplotlib': 'å¯è§†åŒ–',
        'seaborn': 'ç»Ÿè®¡å¯è§†åŒ–',
        'jupyter': 'Jupyter Notebook',
        'ipykernel': 'Jupyterå†…æ ¸',
        'tqdm': 'è¿›åº¦æ¡'
    }
    
    results = {}
    
    for package, description in required_packages.items():
        try:
            importlib.import_module(package)
            print(f"   âœ… {package:<12} - {description}")
            results[package] = True
        except ImportError:
            print(f"   âŒ {package:<12} - {description}")
            results[package] = False
    
    missing = [pkg for pkg, installed in results.items() if not installed]
    if missing:
        print(f"\nâš ï¸ ç¼ºå°‘åŒ…: {', '.join(missing)}")
        print("å»ºè®®è¿è¡Œ: pip install -r requirements.txt")
    
    return results

def check_project_structure() -> Dict[str, Any]:
    """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
    print("\nğŸ“ æ£€æŸ¥é¡¹ç›®ç»“æ„...")
    
    required_files = [
        "config.py",
        "requirements.txt", 
        "environment.yml",
        ".gitignore",
        "README.md",
        "EdgeRLHF_Research_Report.md"
    ]
    
    required_dirs = [
        "data",
        "models",
        "models/sft",
        "models/rm",
        "results",
        "logs",
        "scripts"
    ]
    
    notebooks = [
        "00_Setup.ipynb",
        "01_Data_Preparation.ipynb",
        "02_SFT_Finetuning.ipynb",
        "03_Reward_Modeling.ipynb",
        "04_PPO_Alignment.ipynb"
    ]
    
    results = {
        'files': {},
        'directories': {},
        'notebooks': {}
    }
    
    # æ£€æŸ¥æ–‡ä»¶
    for file_path in required_files:
        exists = Path(file_path).exists()
        size = Path(file_path).stat().st_size / 1024 if exists else 0  # KB
        print(f"   {'âœ…' if exists else 'âŒ'} {file_path:<30} {f'({size:.1f} KB)' if exists else '(ä¸å­˜åœ¨)'}")
        results['files'][file_path] = {'exists': exists, 'size_kb': size}
    
    # æ£€æŸ¥ç›®å½•
    for dir_path in required_dirs:
        exists = Path(dir_path).exists()
        print(f"   {'âœ…' if exists else 'âŒ'} {dir_path}/")
        results['directories'][dir_path] = exists
    
    # æ£€æŸ¥Notebook
    for notebook in notebooks:
        exists = Path(notebook).exists()
        size = Path(notebook).stat().st_size / 1024 if exists else 0  # KB
        print(f"   {'âœ…' if exists else 'âŒ'} {notebook:<25} {f'({size:.1f} KB)' if exists else '(ä¸å­˜åœ¨)'}")
        results['notebooks'][notebook] = {'exists': exists, 'size_kb': size}
    
    return results

def check_data_integrity() -> Dict[str, Any]:
    """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
    
    data_files = [
        ("data/train_prefs.jsonl", "è®­ç»ƒåå¥½æ•°æ®"),
        ("data/test_prefs.jsonl", "æµ‹è¯•åå¥½æ•°æ®")
    ]
    
    results = {}
    
    for file_path, description in data_files:
        path = Path(file_path)
        file_result = {'description': description}
        
        if not path.exists():
            print(f"   âŒ {file_path} - æ–‡ä»¶ä¸å­˜åœ¨")
            file_result['exists'] = False
            results[file_path] = file_result
            continue
        
        file_result['exists'] = True
        file_result['size_mb'] = path.stat().st_size / 1024**2
        
        try:
            # è¯»å–å¹¶éªŒè¯JSONLæ ¼å¼
            lines = []
            with open(path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        lines.append(data)
                        if line_num > 5:  # åªæ£€æŸ¥å‰5è¡Œç»“æ„
                            break
                    except json.JSONDecodeError as e:
                        print(f"   âŒ {file_path} - ç¬¬{line_num}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}")
                        file_result['valid'] = False
                        break
                else:
                    file_result['valid'] = True
            
            if file_result['valid']:
                # ç»Ÿè®¡æ€»è¡Œæ•°
                with open(path, 'r', encoding='utf-8') as f:
                    file_result['total_lines'] = sum(1 for _ in f)
                
                # æ£€æŸ¥æ•°æ®ç»“æ„
                if lines:
                    sample = lines[0]
                    required_keys = ['chosen', 'rejected']
                    has_all_keys = all(key in sample for key in required_keys)
                    file_result['structure_valid'] = has_all_keys
                    
                    if has_all_keys:
                        print(f"   âœ… {file_path} - {file_result['total_lines']} æ¡è®°å½• ({file_result['size_mb']:.1f} MB)")
                    else:
                        print(f"   âš ï¸ {file_path} - æ•°æ®ç»“æ„ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…éœ€å­—æ®µ")
                else:
                    print(f"   âš ï¸ {file_path} - æ–‡ä»¶ä¸ºç©º")
                    file_result['structure_valid'] = False
        
        except Exception as e:
            print(f"   âŒ {file_path} - è¯»å–é”™è¯¯: {e}")
            file_result['valid'] = False
        
        results[file_path] = file_result
    
    return results

def check_model_files() -> Dict[str, Any]:
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("\nğŸ¤– æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    
    model_paths = [
        ("models/sft", "SFTå¾®è°ƒæ¨¡å‹"),
        ("models/rm/bf16", "BF16å¥–åŠ±æ¨¡å‹"),
        ("models/rm/int8", "INT8å¥–åŠ±æ¨¡å‹"),
        ("models/rm/int4", "INT4å¥–åŠ±æ¨¡å‹")
    ]
    
    results = {}
    
    for model_path, description in model_paths:
        path = Path(model_path)
        model_result = {'description': description, 'path': model_path}
        
        if not path.exists():
            print(f"   âŒ {model_path} - ç›®å½•ä¸å­˜åœ¨")
            model_result['exists'] = False
            results[model_path] = model_result
            continue
        
        model_result['exists'] = True
        
        # æ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶
        key_files = [
            "adapter_model.safetensors",
            "adapter_config.json",
            "training_args.bin"
        ]
        
        found_files = []
        total_size = 0
        
        for file_name in key_files:
            file_path = path / file_name
            if file_path.exists():
                size = file_path.stat().st_size / 1024**2  # MB
                found_files.append((file_name, size))
                total_size += size
        
        model_result['files'] = found_files
        model_result['total_size_mb'] = total_size
        
        if found_files:
            files_str = ", ".join([f"{name}({size:.1f}MB)" for name, size in found_files])
            print(f"   âœ… {model_path} - {files_str}")
            model_result['valid'] = True
        else:
            print(f"   âš ï¸ {model_path} - ç›®å½•å­˜åœ¨ä½†ç¼ºå°‘å…³é”®æ–‡ä»¶")
            model_result['valid'] = False
        
        results[model_path] = model_result
    
    return results

def check_config_validity() -> Dict[str, Any]:
    """æ£€æŸ¥é…ç½®æ–‡ä»¶æœ‰æ•ˆæ€§"""
    print("\nâš™ï¸ æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    
    results = {'config_importable': False}
    
    try:
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
        sys.path.insert(0, str(Path.cwd()))
        
        from config import (
            MODEL_CONFIG, SFT_CONFIG, REWARD_MODEL_CONFIG,
            PPO_CONFIG, EXPERIMENT_CONFIG, HARDWARE_CONFIG
        )
        
        print("   âœ… é…ç½®æ–‡ä»¶å¯¼å…¥æˆåŠŸ")
        results['config_importable'] = True
        
        # æ£€æŸ¥é…ç½®å®Œæ•´æ€§
        configs_to_check = {
            'MODEL_CONFIG': MODEL_CONFIG,
            'SFT_CONFIG': SFT_CONFIG, 
            'REWARD_MODEL_CONFIG': REWARD_MODEL_CONFIG,
            'PPO_CONFIG': PPO_CONFIG,
            'EXPERIMENT_CONFIG': EXPERIMENT_CONFIG,
            'HARDWARE_CONFIG': HARDWARE_CONFIG
        }
        
        for config_name, config in configs_to_check.items():
            if hasattr(config, '__dict__'):
                print(f"   âœ… {config_name} - é…ç½®å¯¹è±¡å®Œæ•´")
                results[config_name.lower()] = True
            else:
                print(f"   âŒ {config_name} - é…ç½®å¯¹è±¡æ— æ•ˆ")
                results[config_name.lower()] = False
        
        # éªŒè¯å…³é”®é…ç½®å€¼
        max_memory_mb = int(HARDWARE_CONFIG.vram_gb * 1024 * HARDWARE_CONFIG.max_memory_allocation)
        if max_memory_mb <= 8192:
            print(f"   âœ… å†…å­˜é…ç½®é€‚åˆ8GB GPU: {max_memory_mb}MB")
        else:
            print(f"   âš ï¸ å†…å­˜é…ç½®å¯èƒ½è¶…å‡º8GB GPUé™åˆ¶: {max_memory_mb}MB")
        
    except ImportError as e:
        print(f"   âŒ é…ç½®æ–‡ä»¶å¯¼å…¥å¤±è´¥: {e}")
        results['config_importable'] = False
    except Exception as e:
        print(f"   âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        results['config_error'] = str(e)
    
    return results

def check_git_status() -> Dict[str, Any]:
    """æ£€æŸ¥GitçŠ¶æ€"""
    print("\nğŸ”„ æ£€æŸ¥GitçŠ¶æ€...")
    
    results = {}
    
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºGitä»“åº“
        result = subprocess.run(
            ["git", "rev-parse", "--is-inside-work-tree"],
            capture_output=True, text=True, cwd=Path.cwd()
        )
        
        if result.returncode == 0:
            print("   âœ… Gitä»“åº“å·²åˆå§‹åŒ–")
            results['is_git_repo'] = True
            
            # æ£€æŸ¥è¿œç¨‹ä»“åº“
            result = subprocess.run(
                ["git", "remote", "-v"],
                capture_output=True, text=True, cwd=Path.cwd()
            )
            
            if result.stdout.strip():
                print(f"   âœ… è¿œç¨‹ä»“åº“å·²é…ç½®")
                results['has_remote'] = True
            else:
                print("   âš ï¸ æœªé…ç½®è¿œç¨‹ä»“åº“")
                results['has_remote'] = False
            
            # æ£€æŸ¥å·¥ä½œç›®å½•çŠ¶æ€
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True, text=True, cwd=Path.cwd()
            )
            
            if result.stdout.strip():
                print("   âš ï¸ æœ‰æœªæäº¤çš„æ›´æ”¹")
                results['clean_working_dir'] = False
            else:
                print("   âœ… å·¥ä½œç›®å½•å¹²å‡€")
                results['clean_working_dir'] = True
                
        else:
            print("   âŒ ä¸æ˜¯Gitä»“åº“")
            results['is_git_repo'] = False
            
    except FileNotFoundError:
        print("   âŒ Gitæœªå®‰è£…")
        results['git_installed'] = False
    except Exception as e:
        print(f"   âŒ Gitæ£€æŸ¥å¤±è´¥: {e}")
        results['git_error'] = str(e)
    
    return results

def run_quick_tests() -> Dict[str, Any]:
    """è¿è¡Œå¿«é€ŸåŠŸèƒ½æµ‹è¯•"""
    print("\nğŸ§ª è¿è¡Œå¿«é€ŸåŠŸèƒ½æµ‹è¯•...")
    
    results = {}
    
    # æµ‹è¯•PyTorchåŸºæœ¬åŠŸèƒ½
    try:
        import torch
        
        # åˆ›å»ºå°å¼ é‡æµ‹è¯•
        x = torch.randn(2, 3)
        y = torch.randn(3, 2)
        z = torch.mm(x, y)
        
        print("   âœ… PyTorchåŸºæœ¬è¿ç®—æµ‹è¯•é€šè¿‡")
        results['pytorch_basic'] = True
        
        # æµ‹è¯•CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            x_cuda = x.cuda()
            y_cuda = y.cuda()
            z_cuda = torch.mm(x_cuda, y_cuda)
            print("   âœ… CUDAè¿ç®—æµ‹è¯•é€šè¿‡")
            results['cuda_computation'] = True
        else:
            results['cuda_computation'] = False
            
    except Exception as e:
        print(f"   âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
        results['pytorch_basic'] = False
    
    # æµ‹è¯•TransformersåŠ è½½
    try:
        from transformers import AutoTokenizer
        tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
        tokens = tokenizer("Hello world", return_tensors="pt")
        print("   âœ… Transformers tokenizeræµ‹è¯•é€šè¿‡")
        results['transformers_basic'] = True
    except Exception as e:
        print(f"   âŒ Transformersæµ‹è¯•å¤±è´¥: {e}")
        results['transformers_basic'] = False
    
    return results

def generate_report(all_results: Dict[str, Any]) -> str:
    """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
    report = ["# EdgeRLHFé¡¹ç›®éªŒè¯æŠ¥å‘Š", ""]
    report.append(f"éªŒè¯æ—¶é—´: {Path.cwd()}")
    report.append("")
    
    # ç»Ÿè®¡å„éƒ¨åˆ†çŠ¶æ€
    sections = [
        ("ç¯å¢ƒæ£€æŸ¥", all_results.get('environment', {})),
        ("åŒ…æ£€æŸ¥", all_results.get('packages', {})),
        ("é¡¹ç›®ç»“æ„", all_results.get('structure', {})),
        ("æ•°æ®å®Œæ•´æ€§", all_results.get('data', {})),
        ("æ¨¡å‹æ–‡ä»¶", all_results.get('models', {})),
        ("é…ç½®æ–‡ä»¶", all_results.get('config', {})),
        ("GitçŠ¶æ€", all_results.get('git', {})),
        ("åŠŸèƒ½æµ‹è¯•", all_results.get('tests', {}))
    ]
    
    # è®¡ç®—æ€»ä½“å¾—åˆ†
    total_score = 0
    max_score = 0
    
    for section_name, section_data in sections:
        if isinstance(section_data, dict):
            section_score = sum(1 for v in section_data.values() if v is True)
            section_max = len([v for v in section_data.values() if isinstance(v, bool)])
            total_score += section_score
            max_score += section_max
            
            if section_max > 0:
                percentage = (section_score / section_max) * 100
                status = "âœ…" if percentage >= 80 else "âš ï¸" if percentage >= 60 else "âŒ"
                report.append(f"- {status} {section_name}: {section_score}/{section_max} ({percentage:.1f}%)")
    
    if max_score > 0:
        overall_percentage = (total_score / max_score) * 100
        overall_status = "âœ…" if overall_percentage >= 80 else "âš ï¸" if overall_percentage >= 60 else "âŒ"
        report.append("")
        report.append(f"## æ€»ä½“çŠ¶æ€: {overall_status} {total_score}/{max_score} ({overall_percentage:.1f}%)")
    
    return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” EdgeRLHFé¡¹ç›®éªŒè¯å·¥å…·")
    print("=" * 50)
    
    all_results = {}
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    all_results['environment'] = check_environment()
    all_results['packages'] = check_packages()
    all_results['structure'] = check_project_structure()
    all_results['data'] = check_data_integrity()
    all_results['models'] = check_model_files()
    all_results['config'] = check_config_validity()
    all_results['git'] = check_git_status()
    all_results['tests'] = run_quick_tests()
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 50)
    report = generate_report(all_results)
    print(report)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = Path("logs/validation_results.json")
    results_file.parent.mkdir(exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return all_results

if __name__ == "__main__":
    main() 