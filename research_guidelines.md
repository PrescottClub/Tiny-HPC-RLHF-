# EdgeRLHF Research Guidelines

## ðŸŽ¯ ç ”ç©¶ç›®æ ‡
EdgeRLHFé¡¹ç›®è‡´åŠ›äºŽåœ¨æ¶ˆè´¹çº§GPUä¸Šå®žçŽ°é«˜è´¨é‡çš„RLHFè®­ç»ƒï¼Œé™ä½ŽAIå¯¹é½ç ”ç©¶çš„é—¨æ§›ã€‚

## ðŸ“Š å®žéªŒè§„èŒƒ

### å†…å­˜ç®¡ç†åŽŸåˆ™
- **VRAMé™åˆ¶**: ä¸¥æ ¼æŽ§åˆ¶åœ¨8GBä»¥å†… (RTX 4060)
- **æ‰¹æ¬¡å¤§å°**: ä¼˜å…ˆä½¿ç”¨gradient accumulationè€Œéžå¤§æ‰¹æ¬¡
- **æ¨¡åž‹é‡åŒ–**: ç³»ç»Ÿæ€§æ¯”è¾ƒBF16/INT8/INT4çš„æ•ˆæžœ
- **æ£€æŸ¥ç‚¹**: å®šæœŸä¿å­˜ï¼Œé¿å…è®­ç»ƒä¸­æ–­é€ æˆæŸå¤±

### å¯å¤çŽ°æ€§è¦æ±‚
```python
# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

# å›ºå®šCUDAç®—æ³•
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

### è¯„ä¼°æŒ‡æ ‡
1. **å¥–åŠ±æ¨¡åž‹è´¨é‡**
   - å‡†ç¡®çŽ‡ (Accuracy)
   - AUC-ROC
   - æ ¡å‡†è¯¯å·® (Calibration Error)

2. **PPOè®­ç»ƒæ•ˆæžœ**
   - å¹³å‡å¥–åŠ±åˆ†æ•°
   - KLæ•£åº¦ (ä¸ŽSFTæ¨¡åž‹)
   - å“åº”è´¨é‡äººå·¥è¯„ä¼°

3. **èµ„æºæ•ˆçŽ‡**
   - VRAMå³°å€¼ä½¿ç”¨é‡
   - è®­ç»ƒæ—¶é—´
   - æ¨¡åž‹å¤§å°

## ðŸ›¡ï¸ å®‰å…¨è€ƒè™‘

### æ•°æ®å®‰å…¨
- ä½¿ç”¨å…¬å¼€æ•°æ®é›† (Anthropic/hh-rlhf)
- é¿å…è®­ç»ƒæ•°æ®æ³„éœ²
- å®šæœŸæ£€æŸ¥æ¨¡åž‹è¾“å‡ºçš„å®‰å…¨æ€§

### è®­ç»ƒç¨³å®šæ€§
- ç›‘æŽ§æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
- è®¾ç½®åˆç†çš„å­¦ä¹ çŽ‡è°ƒåº¦
- ä½¿ç”¨æ¢¯åº¦è£å‰ªé˜²æ­¢è®­ç»ƒå´©æºƒ

## ðŸ”¬ å®žéªŒè®°å½•

### å¿…é¡»è®°å½•çš„ä¿¡æ¯
- ç¡¬ä»¶é…ç½® (GPUåž‹å·ã€VRAMã€é©±åŠ¨ç‰ˆæœ¬)
- è½¯ä»¶çŽ¯å¢ƒ (Pythonã€PyTorchã€transformersç‰ˆæœ¬)
- è¶…å‚æ•°è®¾ç½®
- è®­ç»ƒæ›²çº¿å’Œæœ€ç»ˆæŒ‡æ ‡
- å¼‚å¸¸æƒ…å†µå’Œè§£å†³æ–¹æ¡ˆ

### æ–‡æ¡£æ ¼å¼
```json
{
  "experiment_id": "exp_001",
  "date": "2024-01-01",
  "model_config": {
    "base_model": "distilgpt2",
    "precision": "bf16",
    "lora_rank": 16
  },
  "training_config": {
    "batch_size": 32,
    "learning_rate": 1e-4,
    "epochs": 3
  },
  "results": {
    "final_reward": 0.35,
    "kl_divergence": 0.15,
    "training_time": "35min"
  }
}
```

## ðŸ’¡ ä¼˜åŒ–ç­–ç•¥

### å†…å­˜ä¼˜åŒ–
1. **QLoRA**: 4bité‡åŒ– + LoRAå¾®è°ƒ
2. **Gradient Checkpointing**: æ—¶é—´æ¢ç©ºé—´
3. **DeepSpeed ZeRO**: åˆ†å¸ƒå¼ä¼˜åŒ–å™¨çŠ¶æ€
4. **æ¨¡åž‹å¹¶è¡Œ**: å¿…è¦æ—¶åˆ†å‰²å¤§æ¨¡åž‹

### è®­ç»ƒåŠ é€Ÿ
1. **æ··åˆç²¾åº¦**: BF16è®­ç»ƒ
2. **ç¼–è¯‘ä¼˜åŒ–**: torch.compile()
3. **æ•°æ®åŠ è½½**: å¤šè¿›ç¨‹DataLoader
4. **ç¼“å­˜ç­–ç•¥**: é¢„å¤„ç†æ•°æ®ç¼“å­˜

## ðŸš¨ å¸¸è§é—®é¢˜è§£å†³

### CUDA OOM (æ˜¾å­˜ä¸è¶³)
```python
# é™ä½Žæ‰¹æ¬¡å¤§å°
batch_size = batch_size // 2

# å¢žåŠ æ¢¯åº¦ç´¯ç§¯
gradient_accumulation_steps *= 2

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()
```

### è®­ç»ƒä¸ç¨³å®š
```python
# é™ä½Žå­¦ä¹ çŽ‡
learning_rate *= 0.5

# å¢žåŠ é¢„çƒ­æ­¥æ•°
warmup_steps = total_steps * 0.1

# ä½¿ç”¨æ¢¯åº¦è£å‰ª
max_grad_norm = 0.5
```

### å¥–åŠ±æ¨¡åž‹è¿‡æ‹Ÿåˆ
```python
# å¢žåŠ dropout
dropout = 0.1

# æ—©åœç­–ç•¥
early_stopping_patience = 3

# æ•°æ®å¢žå¼º
data_augmentation = True
```

## ðŸ“ˆ æ€§èƒ½åŸºå‡†

### ç›®æ ‡æŒ‡æ ‡
- **å¥–åŠ±åˆ†æ•°**: > 0.3 (ç›¸æ¯”SFT baseline 0.12)
- **KLæ•£åº¦**: < 0.2 (ä¿æŒä¸ŽåŽŸæ¨¡åž‹çš„ç›¸ä¼¼æ€§)
- **è®­ç»ƒæ—¶é—´**: < 1å°æ—¶ (å®Œæ•´PPOè®­ç»ƒ)
- **VRAMä½¿ç”¨**: < 8GBå³°å€¼

### å¯¹æ¯”åŸºå‡†
| é…ç½® | å¥–åŠ±åˆ†æ•° | KLæ•£åº¦ | è®­ç»ƒæ—¶é—´ | VRAM |
|------|----------|--------|----------|------|
| BF16 | 0.35 | 0.15 | 35min | 4.7GB |
| INT8 | 0.31 | 0.18 | 40min | 3.2GB |
| INT4 | 0.28 | 0.22 | 45min | 2.1GB |

## ðŸŽ“ å­¦ä¹ èµ„æº

### æŽ¨èé˜…è¯»
1. InstructGPTè®ºæ–‡ (OpenAI, 2022)
2. Constitutional AI (Anthropic, 2022)  
3. Training language models to follow instructions with human feedback
4. Deep reinforcement learning from human preferences

### ç›¸å…³é¡¹ç›®
- [trl](https://github.com/huggingface/trl): HuggingFace RLHFåº“
- [DeepSpeed](https://github.com/microsoft/DeepSpeed): å†…å­˜ä¼˜åŒ–
- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes): é‡åŒ–è®­ç»ƒ 